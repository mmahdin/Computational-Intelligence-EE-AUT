{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import ConcatDataset, random_split, DataLoader\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# import pandas as pd\n",
    "\n",
    "# # Load the training dataset\n",
    "# train_csv = 'imdb_train.csv'  # Replace with actual path\n",
    "# train_data = pd.read_csv(train_csv)\n",
    "\n",
    "# # Count unique tokens in the 'tokenized' column\n",
    "# # Assuming 'tokenized' column contains lists of tokens as strings, e.g., \"[1, 23, 456]\"\n",
    "# all_tokens = []\n",
    "# for tokens in train_data['tokenized']:\n",
    "#     token_list = eval(tokens)  # Convert the string representation to a list\n",
    "#     all_tokens.extend(token_list)\n",
    "\n",
    "# # Calculate the vocabulary size\n",
    "# vocab_size = len(set(all_tokens))\n",
    "# print(vocab_size)\n",
    "\n",
    "# # Load the training dataset\n",
    "# train_csv = 'imdb_train.csv'  # Replace with actual path\n",
    "# train_data = pd.read_csv(train_csv)\n",
    "\n",
    "# # Find the maximum sequence length in the 'tokenized' column\n",
    "# # Assuming 'tokenized' column contains lists of tokens as strings, e.g., \"[1, 23, 456]\"\n",
    "# max_seq_length = max(len(eval(tokens)) for tokens in train_data['tokenized'])\n",
    "# print(\"Maximum Sequence Length:\", max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataset class with padding\n",
    "class SentimentAnalysisDataset(Dataset):\n",
    "    def __init__(self, csv_file, max_length=2494, vocab_size=88585):\n",
    "        # Load data from CSV\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.max_length = max_length  # Set max length for padding\n",
    "        self.vocab_size = vocab_size  # Maximum vocab index\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the row by index\n",
    "        review = self.data.loc[idx, 'review']\n",
    "        tokenized = eval(self.data.loc[idx, 'tokenized'])  # assuming tokenized is stored as a string of list\n",
    "        label = self.data.loc[idx, 'label']\n",
    "        \n",
    "        # Ensure token indices are within the vocab_size range\n",
    "        tokenized = [min(token, self.vocab_size - 1) for token in tokenized]\n",
    "        \n",
    "        # Convert to tensor and pad, move to the appropriate device\n",
    "        tokenized_tensor = torch.tensor(tokenized, dtype=torch.long).to(device)\n",
    "        tokenized_tensor = F.pad(\n",
    "            tokenized_tensor, (0, self.max_length - len(tokenized_tensor)), value=0\n",
    "        )  # Pad with zeros up to max_length\n",
    "        \n",
    "        # Convert label to tensor and move to device\n",
    "        label_tensor = torch.tensor(label, dtype=torch.long).to(device)\n",
    "        \n",
    "        return tokenized_tensor, label_tensor\n",
    "\n",
    "# Paths to CSV files\n",
    "train_csv = 'imdb_train.csv'\n",
    "test_csv = 'imdb_test.csv'\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = SentimentAnalysisDataset(train_csv)\n",
    "test_dataset = SentimentAnalysisDataset(test_csv)\n",
    "\n",
    "# Combine train and test datasets\n",
    "combined_dataset = ConcatDataset([train_dataset, test_dataset])\n",
    "\n",
    "# Define split proportions\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "\n",
    "# Calculate dataset sizes\n",
    "train_size = int(train_ratio * len(combined_dataset))\n",
    "val_size = int(val_ratio * len(combined_dataset))\n",
    "test_size = len(combined_dataset) - train_size - val_size\n",
    "\n",
    "# Split combined dataset\n",
    "new_train_dataset, new_val_dataset, new_test_dataset = random_split(\n",
    "    combined_dataset, [train_size, val_size, test_size]\n",
    ")\n",
    "\n",
    "# # Define desired subset sizes\n",
    "# train_subset_size = 1000\n",
    "# val_subset_size = 100\n",
    "# test_subset_size = 100\n",
    "\n",
    "# # Create smaller subsets of the original datasets\n",
    "# new_train_dataset, _ = random_split(new_train_dataset, [train_subset_size, len(new_train_dataset) - train_subset_size])\n",
    "# new_val_dataset, _ = random_split(new_val_dataset, [val_subset_size, len(new_val_dataset) - val_subset_size])\n",
    "# new_test_dataset, _ = random_split(new_test_dataset, [test_subset_size, len(new_test_dataset) - test_subset_size])\n",
    "\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(new_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(new_val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(new_test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Text: torch.Size([2494])\n",
      "Label: tensor(1, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Print one data row from the training dataset\n",
    "sample_index = 0  # Replace with any valid index to print a different row\n",
    "tokenized_tensor, label_tensor = train_dataset[sample_index]\n",
    "\n",
    "print(\"Tokenized Text:\", tokenized_tensor.shape)\n",
    "print(\"Label:\", label_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "  <img src=\"image.png\" alt=\"image description\"/>\n",
    "</div>\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"image-1.png\" alt=\"image description\"/>\n",
    "</div>\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"image-2.png\" alt=\"image description\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the RNN model for sentiment analysis\n",
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "        \"\"\"\n",
    "        N: num batches (sentences).\n",
    "        D: Each token is represented by a D-dimensional embedding vector (embed_size).\n",
    "        T: Maximum sequence length (number of words in each sequence)\n",
    "        H: hidden_size\n",
    "\n",
    "        shape input: (N, T)\n",
    "        shape embeded input: (N, T, D)\n",
    "        \n",
    "        for each word in the sentence:\n",
    "            next_h = torch.tanh(x.mm(Wx) + prev_h.mm(Wh) + b)\n",
    "            {\n",
    "                where:\n",
    "                x:      (N,D)\n",
    "                Wx:     (D,H)\n",
    "                Wh:     (H,H)\n",
    "                b:      (H,)\n",
    "                next_h: (N,H)\n",
    "            }\n",
    "            (This is one step in the image above.)\n",
    "        \n",
    "        This process repeats for all the words in the sentence, so the number of output or hidden states at the end is T.\n",
    "\n",
    "        output: (N, T, H)\n",
    "        \"\"\"\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size) # assigne a vector of embec_size to each word\n",
    "        self.rnn = nn.RNN(embed_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 2)\n",
    "        self.hidden_dim = hidden_size\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        hidden: (N, H)\n",
    "        \"\"\"        \n",
    "        x = self.embedding(x)\n",
    "        output, hidden = self.rnn(x)\n",
    "        prediction = self.fc(output[:, -1, :]) \n",
    "        return prediction\n",
    "    \n",
    "\n",
    "# Define the RNN model for sentiment analysis\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \"\"\"\n",
    "        N: num batches (sentences).\n",
    "        D: Each token is represented by a D-dimensional embedding vector (embed_size).\n",
    "        T: Maximum sequence length (number of words in each sequence)\n",
    "        H: hidden_size\n",
    "\n",
    "        shape input: (N, T)\n",
    "        shape embeded input: (N, T, D)\n",
    "        \n",
    "        for each word in the sentence:\n",
    "            next_h = torch.tanh(x.mm(Wx) + prev_h.mm(Wh) + b)\n",
    "            {\n",
    "                where:\n",
    "                x:      (N,D)\n",
    "                Wx:     (D,H)\n",
    "                Wh:     (H,H)\n",
    "                b:      (H,)\n",
    "                next_h: (N,H)\n",
    "            }\n",
    "            (This is one step in the image above.)\n",
    "        \n",
    "        This process repeats for all the words in the sentence, so the number of output or hidden states at the end is T.\n",
    "\n",
    "        output: (N, T, H)\n",
    "        \"\"\"\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size) # assigne a vector of embec_size to each word\n",
    "        self.rnn = nn.RNN(embed_size, hidden_size, batch_first=True)\n",
    "\n",
    "        self.hidden_dim = hidden_size\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        hidden: (N, H)\n",
    "        \"\"\"        \n",
    "        x = self.embedding(x)\n",
    "        output, hidden = self.rnn(x)\n",
    "        return hidden\n",
    "    \n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, output_dim, hidden_dim):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.rnn = nn.RNN(hidden_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "    def forward(self, hidden):\n",
    "        batch_size = hidden.size(1)\n",
    "        input = torch.zeros(batch_size, 1, self.hidden_dim).to(hidden.device)  # [batch_size, 1, hidden_dim]\n",
    "        outputs, hidden = self.rnn(input, hidden)\n",
    "        \n",
    "        # Pass final RNN output to linear layer\n",
    "        prediction = self.fc(outputs.squeeze(1))  # prediction = [batch_size, output_dim]\n",
    "        return prediction\n",
    "    \n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, src):\n",
    "        hidden = self.encoder(src)\n",
    "        output = self.decoder(hidden)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "Train Loss: 0.6960\n",
      "Val Loss: 0.6945 | Val Accuracy: 0.4993\n",
      "Epoch 2/2\n",
      "Train Loss: 0.6957\n",
      "Val Loss: 0.6952 | Val Accuracy: 0.4993\n"
     ]
    }
   ],
   "source": [
    "# Set parameters\n",
    "vocab_size = 88585  # As per your dataset\n",
    "embed_size = 128\n",
    "hidden_size = 64\n",
    "output_size = 2  # Assuming binary classification: positive or negative sentiment\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "# Instantiate the model, define the loss function and optimizer\n",
    "encoder = EncoderRNN(vocab_size, embed_size, hidden_size)\n",
    "decoder = DecoderRNN(output_size, hidden_size)\n",
    "model = Seq2Seq(encoder, decoder).to(device)\n",
    "model = SimpleRNN(vocab_size, embed_size, hidden_size).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "def train(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()  # Set the model to training mode\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        inputs, labels = batch\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    return avg_loss\n",
    "\n",
    "def evaluate(model, val_loader, criterion, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    epoch_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            inputs, labels = batch\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            # Save predictions and true labels for accuracy calculation\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_loss = epoch_loss / len(val_loader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "# Set number of epochs\n",
    "num_epochs = 2\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    train_loss = train(model, train_loader, criterion, optimizer, device)\n",
    "    \n",
    "    # Validation phase\n",
    "    val_loss, val_accuracy = evaluate(model, val_loader, criterion, device)\n",
    "    \n",
    "    # Print training and validation metrics\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f} | Val Accuracy: {val_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
